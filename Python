import os
import sqlite3
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from pinecone.grpc import PineconeGRPC as Pinecone
from pinecone import ServerlessSpec
from langchain_pinecone import PineconeVectorStore
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter

# =========üåç Vari√°veis de ambiente =========
openai_key = os.getenv('OPENAI_API_KEY')
pinecone_key = os.getenv('PINECONE_API_KEY')
DB_PATH = os.path.join('database', 'app_data.db')

# =========üß† Configura√ß√£o b√°sica =========
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)

# =========üîê Inicializa√ß√£o do Pinecone =========
def init_pinecone(index_name: str = 'meus-documentos') -> PineconeVectorStore:
    pc = Pinecone(pinecone_key)
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=1536,
            metric='cosine',
            spec=ServerlessSpec(cloud='aws', region='us-east-1')
        )
    embeddings = OpenAIEmbeddings()
    vector_store = PineconeVectorStore.from_existing_index(
        index_name=index_name,
        embedding=embeddings
    )
    return vector_store

vector_store = init_pinecone()

# =========üìÑ Prompt Template =========
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
Voc√™ √© um assistente de IA especializado em leitura e an√°lise de documentos PDF. Seu objetivo √© ajudar o usu√°rio a encontrar informa√ß√µes com base exclusivamente no conte√∫do dos arquivos fornecidos.

IMPORTANTE:
- Use apenas o conte√∫do extra√≠do dos PDFs indexados.
- N√ÉO utilize informa√ß√µes externas ou invente fatos.
- Suas respostas devem ser educadas, claras e √∫teis.

---

## CONTEXTO HIST√ìRICO:

{context}

---

## PERGUNTA DO USU√ÅRIO:

{question}

---

## FORMATO ESPERADO:

- [resposta clara]. (p√°gina X, se√ß√£o: t√≠tulo)
> "trecho citado, se aplic√°vel"

Se desejar mais detalhes, posso ajudar!
"""
)

# =========üì¶ Banco de dados =========
def buscar_historico(pdf_id: str, n: int = 5) -> list:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT question, answer FROM qas WHERE pdf_id = ? ORDER BY id DESC LIMIT ?",
        (pdf_id, n)
    )
    rows = cur.fetchall()
    conn.close()
    return list(reversed(rows))

# =========üì• Fun√ß√£o: Indexar PDF =========
def adicionar_pdf(caminho_pdf: str, pdf_id: str = None) -> str:
    try:
        print(f"[DEBUG] Iniciando leitura do PDF: {caminho_pdf}")
        loader = PyPDFLoader(caminho_pdf)
        pages = loader.load()

        if not pages:
            return "Erro: PDF vazio ou ileg√≠vel."

        docs = text_splitter.split_documents(pages)

        # Adiciona metadado pdf_id como string
        for d in docs:
            d.metadata = {
                'file_name': os.path.basename(caminho_pdf),
                'pdf_id': str(pdf_id)
            }

        print(f"[DEBUG] pdf_id atribu√≠do nos metadados: {docs[0].metadata if docs else 'N/A'}")

        vector_store.add_documents(docs)

        print(f"[INFO] {len(docs)} fragmentos adicionados com pdf_id={pdf_id}")
        return f"Sucesso: {len(docs)} fragmentos indexados."

    except Exception as e:
        print(f"[ERRO] Falha ao processar PDF {caminho_pdf}: {e}")
        return f"Erro: {str(e)}"

# =========ü§ñ Fun√ß√£o: Perguntar =========
def perguntar(pergunta: str, pdf_id: str = None) -> str:
    try:
        print(f"[DEBUG] Iniciando pergunta para pdf_id={pdf_id}")
        hist = buscar_historico(pdf_id) if pdf_id else []
        context = '\n'.join([f"Q: {q}\nA: {a}" for q, a in hist]) or "Nenhuma intera√ß√£o anterior."

        filtro = {'pdf_id': str(pdf_id)} if pdf_id else {}
        print(f"[DEBUG] Usando filtro no retriever: {filtro}")

        retriever = vector_store.as_retriever(
            search_kwargs={'k': 8, 'filter': filtro}
        )

        # Verificar documentos recuperados (DEBUG)
        docs_test = retriever.get_relevant_documents(pergunta)
        print(f"[DEBUG] Documentos retornados: {len(docs_test)}")
        for doc in docs_test[:3]:
            print(f"[DEBUG] Metadados recuperados: {doc.metadata}")

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type='stuff',
            retriever=retriever,
            chain_type_kwargs={'prompt': prompt_template},
            return_source_documents=False
        )

        result = qa_chain.invoke({
            'query': pergunta.strip(),
            'context': context
        })

        return result.get('result', '‚ùå N√£o encontrei essa informa√ß√£o no PDF especificado.')

    except Exception as e:
        print(f"[ERRO] Falha ao responder pergunta: {e}")
        return f"Erro: {str(e)}"
